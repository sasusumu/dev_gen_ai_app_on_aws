{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Amazon Titan Embeddings を使用したベクトル化\n",
    "埋め込みモデルの Amazon Titan Embeddings を使用して、テキストをベクトル化します。\n",
    "ベクトル化されたテキストの距離を比較することで、テキストの類似度を計算することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T02:22:13.864603Z",
     "iopub.status.busy": "2025-10-24T02:22:13.864229Z",
     "iopub.status.idle": "2025-10-24T02:22:13.869286Z",
     "shell.execute_reply": "2025-10-24T02:22:13.868279Z",
     "shell.execute_reply.started": "2025-10-24T02:22:13.864574Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "AWS Python SDK の invoke_model を使用してベクトル化したいテキストを埋め込みモデルにインプットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T02:22:14.864709Z",
     "iopub.status.busy": "2025-10-24T02:22:14.864442Z",
     "iopub.status.idle": "2025-10-24T02:22:14.874670Z",
     "shell.execute_reply": "2025-10-24T02:22:14.873932Z",
     "shell.execute_reply.started": "2025-10-24T02:22:14.864689Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "\n",
    "# 埋め込みを行う基盤モデルを使用\n",
    "modelId=\"amazon.titan-embed-text-v1\"\n",
    "# modelId=\"amazon.titan-embed-text-v2:0\" ラボ環境では使用不可\n",
    "\n",
    "# 文の埋め込みベクトルを生成する関数\n",
    "def sen2vec(sentence):\n",
    "    # Convert the given sentence to a vector representation using a text embedding model.  \n",
    "    input_body = {\"inputText\": sentence}\n",
    "    try:\n",
    "        response = bedrock_client.invoke_model(\n",
    "            body=json.dumps(input_body),\n",
    "            modelId=modelId,\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "            )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        vector = np.array(response_body.get(\"embedding\"))\n",
    "        return vector\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "サンプルファイル documents-jp.txt に、5つの文章が保存されているので、それぞれをベクトル化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T02:22:15.775530Z",
     "iopub.status.busy": "2025-10-24T02:22:15.775258Z",
     "iopub.status.idle": "2025-10-24T02:22:16.343554Z",
     "shell.execute_reply": "2025-10-24T02:22:16.342930Z",
     "shell.execute_reply.started": "2025-10-24T02:22:15.775507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベクトル化データの配列のサイズ\n",
      "(5, 1536)\n",
      "----\n",
      "ベクトル化データの配列の内容\n",
      "[[ 1.41406250e+00  3.80859375e-02  5.82031250e-01 ...  7.66601562e-02\n",
      "  -9.49218750e-01 -1.75781250e-01]\n",
      " [ 1.03906250e+00 -2.83203125e-01  5.74218750e-01 ... -4.71191406e-02\n",
      "  -5.23437500e-01  2.29492188e-01]\n",
      " [ 1.05468750e+00 -1.19781494e-03  6.75781250e-01 ... -4.33349609e-03\n",
      "  -4.45312500e-01  2.04101562e-01]\n",
      " [ 1.37500000e+00  6.95312500e-01 -5.24902344e-02 ... -1.04980469e-01\n",
      "  -7.65625000e-01  2.24609375e-02]\n",
      " [ 8.43750000e-01  3.43750000e-01  1.99218750e-01 ...  1.70898438e-01\n",
      "   1.58203125e-01  1.17675781e-01]]\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# ドキュメントのファイルを読み込み用の配列を初期化\n",
    "with open(\"documents-jp.txt\") as doc:\n",
    "    num_records = len(doc.readlines())\n",
    "\n",
    "doc_array=np.empty(shape=(num_records), dtype=\"S255\")\n",
    "embed_array = np.zeros(shape=(num_records, 1536)) # v2 では 1536 → 1024\n",
    "\n",
    "# ドキュメントのファイルを読み込み、ベクトル化データを配列へ格納\n",
    "with open(\"documents-jp.txt\") as doc:\n",
    "    for num, line in enumerate(doc, 0):\n",
    "      doc = line.strip('\\n')\n",
    "      doc_array[num] = doc.encode(\"UTF-8\")\n",
    "      embed_array[num] = sen2vec(doc)\n",
    "\n",
    "print(\"ベクトル化データの配列のサイズ\")\n",
    "print(embed_array.shape)\n",
    "print(\"----\")\n",
    "print(\"ベクトル化データの配列の内容\") \n",
    "print(embed_array)\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "類似性検索を使用して類似度を算出します。  \n",
    "行列ベクトルストアから関連ドキュメントを引き出すために類似性検索を使用するインタラクティブなクエリを実行  \n",
    "類似度のしきい値として0.5を使用して、幻影(ハルシネーション)を限定します。  \n",
    "ドキュメントストアのコース名に関連するクエリは、成功した結果につながります。  \n",
    "結果のいずれも0.5のしきい値を超えない場合、「わかりません」が応答になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T02:22:19.724735Z",
     "iopub.status.busy": "2025-10-24T02:22:19.724447Z",
     "iopub.status.idle": "2025-10-24T02:22:19.832481Z",
     "shell.execute_reply": "2025-10-24T02:22:19.831857Z",
     "shell.execute_reply.started": "2025-10-24T02:22:19.724714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "テキスト: AWSの研修\n",
      "\n",
      "類似度\n",
      "[0.85657059 0.73833652 0.61924214 0.37798074 0.32037387]\n",
      "\n",
      "\n",
      "類似性が高いドキュメント:\n",
      "AWSのトレーニングでArchitecting on AWSは3日間のコースです。\n"
     ]
    }
   ],
   "source": [
    "my_text = \"AWSの研修\"\n",
    "#my_text = \"AnyCompany社の勤務に関する情報\"\n",
    "#my_text = \"車のタイヤの交換\"\n",
    "\n",
    "def search_doc(text):\n",
    "    embed_query = sen2vec(text)\n",
    "    denominator = norm(embed_array, axis=1) * norm(embed_query)\n",
    "    similarity = embed_array.dot(embed_query) / denominator\n",
    "    max_value = max(similarity)\n",
    "    max_value_index = similarity.argmax()\n",
    "    print(\"\\nテキスト: \" + text)\n",
    "    print(\"\\n類似度\")\n",
    "    print(similarity)\n",
    "    print(\"\\n\")\n",
    "    if max_value > 0.5:\n",
    "        print(\"類似性が高いドキュメント:\\n\" + doc_array[max_value_index].decode('UTF-8'))\n",
    "    else:\n",
    "        print(\"どのドキュメントも類似性が 50% 未満です。\")\n",
    "    # print(\"\\nSimilarity vector used for document selection\")\n",
    "    # return max_value_index\n",
    "\n",
    "search_doc(my_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "類似度の高いテキストが検索できました。\n",
    "別の文章をインプットして類似度が高い文章を探してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text=\"\"\n",
    "\n",
    "search_doc(my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
